{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b586faf0-ac3f-4ac6-9e6e-2a9a6f0a45f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-15T21:35:39.725267Z",
     "iopub.status.busy": "2024-04-15T21:35:39.725054Z",
     "iopub.status.idle": "2024-04-15T21:35:39.727907Z",
     "shell.execute_reply": "2024-04-15T21:35:39.727554Z",
     "shell.execute_reply.started": "2024-04-15T21:35:39.725212Z"
    }
   },
   "source": [
    "# Save Tables Cleaned Data\n",
    "\n",
    "Notebook used to create and save the tables that are used in the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57a14cc-c0ee-4e1a-b470-06db2d7ebf29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from time import time\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import random\n",
    "tqdm.pandas()\n",
    "\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import seaborn as sns\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "sns.set(style=\"ticks\", context=\"talk\")\n",
    "plt.style.use(\"dark_background\")\n",
    "pd.options.plotting.backend = 'plotly'\n",
    "pio.templates.default = 'plotly_dark+presentation'\n",
    "\n",
    "import matplotlib.dates as dates\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "def form(x,pos):\n",
    "    if x<1e2:\n",
    "        return '%1.0f' % (x)\n",
    "    elif x<1e3:\n",
    "        return '%1.3f' % (x)\n",
    "    elif x<1e6:\n",
    "        return '%1.1fK' % (x * 1e-3)\n",
    "    else:\n",
    "        return '%1.1fM' % (x * 1e-6)\n",
    "formatter = FuncFormatter(form)\n",
    "\n",
    "def plot_(df_,x_column,y_column,x_label,title):\n",
    "    plt.style.use(\"dark_background\")\n",
    "    fig, ax = plt.subplots(figsize=(15, 5))\n",
    "    x_dates = list(df_[x_column])\n",
    "    y_data = df_[y_column]\n",
    "    x_data = x_dates\n",
    "\n",
    "    ax.plot(x_data, y_data, \"co-\", markersize=6,label='dataset')\n",
    "    ax.axvline(pd.Timestamp(2020, 3, 1),color='r')\n",
    "\n",
    "    plt.grid(True, linewidth=0.5)\n",
    "    ax.yaxis.set_major_formatter(formatter)\n",
    "\n",
    "    ax.set_xlabel(x_label,size=20)\n",
    "    ax.set_title(title,size=30)\n",
    "    \n",
    "def read_parquet(name, **args):\n",
    "    path = name\n",
    "    print(f'Reading {name!r}')\n",
    "    tic = time()\n",
    "    df = pd.read_parquet(path, engine='fastparquet', **args)\n",
    "    before = len(df)\n",
    "    # df.drop_duplicates(inplace=True)\n",
    "    toc = time()\n",
    "    after = len(df)\n",
    "        \n",
    "    print(f'Read {len(df):,} rows from {path.stem!r} in {toc-tic:.2f} sec. {before-after:,} duplicates.')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d175207b-a561-4c2e-b280-3dd84c2e09c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"Tables\"):\n",
    "    os.makedirs(\"Tables\")\n",
    "\n",
    "basepath = Path('/N/project/openalex/slices/arxiv-preprints/dec-2024') #folder containing preprint data\n",
    "basepath2 = Path('/N/project/openalex/slices/subset-1990-2022/dec-2024') #folder containing all Openalex data\n",
    "basepath3 = Path('./Tables') #folder where to save final tables\n",
    "basepath4 = Path('/N/project/openalex/ssikdar/processed-snapshots/csv-files/dec-2024') #folder cotaining institutions information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa11bc78-fa3b-4de3-8dd2-c372cfe03dae",
   "metadata": {},
   "source": [
    "## Works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f248cbb3-4b98-4175-a59d-54fa16b74439",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "works = read_parquet(basepath / 'works')\n",
    "\n",
    "preprint_id_set = set(works.index)\n",
    "preprint_work_id_set = set(works.openalex_work_id)\n",
    "print(f'{len(preprint_id_set)} preprint ids')\n",
    "print(f'{len(preprint_work_id_set)} preprint work ids')\n",
    "\n",
    "# #map\n",
    "# preprint_work_id_id_dict = works[['openalex_work_id']].reset_index().set_index('openalex_work_id').to_dict()['work_id']\n",
    "preprint_id_doi_dict = works[['doi']].to_dict()['doi']\n",
    "my_file = \"preprint_id_doi_dict.pickle\"\n",
    "pickle.dump(preprint_id_doi_dict, open(os.path.join(basepath3, my_file), 'wb'))\n",
    "\n",
    "works = works[['preprint_submission_date']].reset_index().rename(columns={'preprint_submission_date':'publication_date'}).drop_duplicates('work_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88024cb0-f4f4-4160-8e09-64c9dcb4233b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "works_all = read_parquet(basepath2 / 'works')\n",
    "works_all = works_all.reset_index()[['work_id','publication_date']]\n",
    "works_all = works_all[~works_all.work_id.isin(preprint_work_id_set)]#delate work_id connected with preprints\n",
    "works_all = pd.concat([works_all,works])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ea6dcb-3c91-4727-b91a-7348e6434fe1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#add month\n",
    "works['publication_date_1'] = pd.to_datetime(pd.DataFrame({'day': 1, \n",
    "                                              'month': works.publication_date.dt.month, \n",
    "                                              'year': works.publication_date.dt.year},\n",
    "                                              index=works.index))\n",
    "\n",
    "works_all['publication_date_1'] = pd.to_datetime(pd.DataFrame({'day': 1, \n",
    "                                              'month': works_all.publication_date.dt.month, \n",
    "                                              'year': works_all.publication_date.dt.year},\n",
    "                                              index=works_all.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491478d7-4968-4f08-b3c4-e100eda09fc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "works = works.sort_values(by='publication_date_1').set_index('publication_date_1')\n",
    "works_all = works_all.sort_values(by='publication_date_1').set_index('publication_date_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a14b5f-1d5c-4803-aef1-2b214fa825ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#save\n",
    "my_file = 'works'\n",
    "works.to_parquet(os.path.join(basepath3, my_file))\n",
    "my_file = 'works_all'\n",
    "works_all.to_parquet(os.path.join(basepath3, my_file))\n",
    "all_work_id_set = set(works_all.work_id)\n",
    "my_file = \"all_work_id_set.pickle\"\n",
    "pickle.dump(all_work_id_set, open(os.path.join(basepath3, my_file), 'wb'))\n",
    "my_file = \"preprint_work_id_set.pickle\"\n",
    "pickle.dump(preprint_work_id_set, open(os.path.join(basepath3, my_file), 'wb'))\n",
    "my_file = \"preprint_id_set.pickle\"\n",
    "pickle.dump(preprint_id_set, open(os.path.join(basepath3, my_file), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6549d47-92d7-45ea-aaa3-9ea5df0b17ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "works_all_month_dict = works_all[['work_id']].reset_index().set_index('work_id').to_dict()['publication_date_1']\n",
    "my_file = \"works_all_month_dict.pickle\"\n",
    "pickle.dump(works_all_month_dict, open(os.path.join(basepath3, my_file), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd143c76-48e8-4d0e-b2b7-d64092d468cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T17:02:27.203664Z",
     "iopub.status.busy": "2025-02-17T17:02:27.203172Z",
     "iopub.status.idle": "2025-02-17T17:02:27.207995Z",
     "shell.execute_reply": "2025-02-17T17:02:27.207459Z",
     "shell.execute_reply.started": "2025-02-17T17:02:27.203644Z"
    }
   },
   "source": [
    "dictionaries <br>\n",
    "* preprint_id_doi_dict: map preprint_id to doi \n",
    "* works_all_month_dict: map works to publication_date \n",
    "* inst_id_name_dict: map institution_id to institution_name\n",
    "* inst_root_map: map institution to its root\n",
    "\n",
    "sets <br>\n",
    "* preprint_work_id_set: set preprints openalex_work_id\n",
    "* preprint_id_set: set preprints ids \n",
    "* all_work_id_set: set works ids\n",
    "* preprint_author_id_set: set authors preprints\n",
    "\n",
    "tables <br>\n",
    "* works: preprints (publication_date_1,work_id,publication_date)\n",
    "* works_all: all papers (publication_date_1,work_work_id,publication_date)\n",
    "* works_authorships_inst2: all works (work_id,author_id,author_name,institution_id,institution_name,publication_year)\n",
    "\n",
    "PAPERS RESTRICTED TO: AUTHORS INFO, REFERENCES INFO, DATA INFO, CONCEPTS INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d96f00-c03b-4f0f-bbf7-0fb42ec8e4ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9a772f3-3cf3-49b5-bfd8-049fbda18243",
   "metadata": {},
   "source": [
    "## Affiliations\n",
    "\n",
    "* Restrict to preprints without missing authors information.\n",
    "* Use root affiliations and threshold 1 km\n",
    "* Infer to each author one affiliation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d2d72a-113e-4d9c-92bd-fd0f146ba917",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#preprint\n",
    "works_authorships = read_parquet(basepath / 'works_authorships',\n",
    "                                 columns=['work_id','author_id','author_name','institution_id','institution_name'], \n",
    "                                 filters=[('author_id', 'isnotnull', True)]        \n",
    "                                )\n",
    "works_authorships['author_id'] = works_authorships['author_id'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58410eaa-d340-4290-aafd-6ca0ef983f22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#all openalex #9mins\n",
    "works_authorships_all = read_parquet(basepath2 / 'works_authorships',\n",
    "                                 columns=['work_id','author_id','author_name','institution_id','institution_name'], \n",
    "                                 filters=[('author_id', 'isnotnull', True)]        \n",
    "                                )\n",
    "works_authorships_all['author_id'] = works_authorships_all['author_id'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8df87ed-aff8-440d-aa7a-069b6c642912",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_file = \"preprint_work_id_set.pickle\"\n",
    "with open(os.path.join(basepath3, my_file),\"rb\") as fp:\n",
    "    preprint_work_id_set = pickle.load(fp)\n",
    "works_authorships_all = works_authorships_all[~works_authorships_all.work_id.isin(preprint_work_id_set)]#delate work_id connected with preprints\n",
    "works_authorships_all = pd.concat([works_authorships_all,works_authorships])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082ffc01-a7b0-4163-bd7c-f8397dd13791",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#for credit allocation calculation #works_id all and list authors - no institutions \n",
    "works_authorships_all['author_id'] = works_authorships_all['author_id'].astype('int')\n",
    "works_authorships_all_drop = works_authorships_all[['work_id','author_id']].drop_duplicates(['work_id','author_id'])\n",
    "works_all = read_parquet(basepath3 / 'works_all')\n",
    "works_authorships_all_drop = works_authorships_all_drop.merge(works_all[['work_id','publication_date']].reset_index(),on='work_id')  #restrict to works with publication_date info\n",
    "works_authorships_all_drop = works_authorships_all_drop.set_index('publication_date_1',drop=True).sort_index()\n",
    "#save\n",
    "my_file = 'works_authorships_all_drop'\n",
    "works_authorships_all_drop.to_parquet(os.path.join(basepath3, my_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eea4066-e0e9-4cfc-8c86-048987cd11bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#institutions not nan\n",
    "works_authorships_all = works_authorships_all[works_authorships_all['institution_id'].notnull()]\n",
    "#works_authorships_all.to_parquet(os.path.join(basepath3, my_file = 'works_authorships_all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cc213c-df25-4837-b8df-d7bfd8cf8d6a",
   "metadata": {},
   "source": [
    "### institutions' tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b637de0-2c6b-4086-9fde-9424d9e6fcd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## institutions' tree  ## substitute every institutions with the root #ex. IU Bloomington and IU\n",
    "institutions_associated_institutions = institutions_geo_df = pd.read_csv(basepath4 / 'institutions_associated_institutions.csv.gz')\n",
    "institutions_associated_institutions = institutions_associated_institutions[institutions_associated_institutions.relationship == 'parent']\n",
    "institutions_associated_institutions = institutions_associated_institutions.drop(columns='relationship')\n",
    "institutions_associated_institutions = institutions_associated_institutions.rename(columns={'associated_institution_id':'parent'})\n",
    "display(institutions_associated_institutions.head())\n",
    "\n",
    "T = nx.from_pandas_edgelist(institutions_associated_institutions,source='parent',target='institution_id',create_using=nx.DiGraph())\n",
    "my_file = \"T.pickle\"\n",
    "pickle.dump(T, open(os.path.join(basepath3, my_file), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de823c0-e682-4377-860f-2ae43eb3651f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_file = \"T.pickle\"\n",
    "with open(os.path.join(basepath3, my_file),\"rb\") as fp:\n",
    "    T = pickle.load(fp)\n",
    "roots = set(v for v, d in T.in_degree() if d == 0)\n",
    "print(f'{len(roots)} roots')\n",
    "print(f'{len(T.nodes)} noods')\n",
    "\n",
    "T2 = T.to_undirected()\n",
    "T2_cc = list(nx.connected_components(T2))\n",
    "count_roots = []\n",
    "for i in tqdm(T2_cc):\n",
    "    count_roots.append(len(i.intersection(roots)))\n",
    "index_1root = list(np.where(np.array(count_roots) == 1)[0])\n",
    "index_no1root = list(np.where(np.array(count_roots) != 1)[0])\n",
    "print(f'components: 1-root {len(index_1root)}, more roots {len(index_no1root)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b6133f-d948-447f-867d-b9c8b8cd58f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#components with just one root: easy\n",
    "#components more roots: each node path up and pick randomly one of the neighbours\n",
    "random.seed(0)\n",
    "\n",
    "d = {}\n",
    "for i in tqdm(range(len(index_no1root))):\n",
    "    i = index_no1root[i]\n",
    "    cc = T2_cc[i]\n",
    "    cc_roots = list(cc.intersection(roots))\n",
    "    d.update(dict(zip(cc_roots,cc_roots)))\n",
    "    cc_noroots = list(cc - set(cc_roots))\n",
    "    for v in cc_noroots:\n",
    "        w = v\n",
    "        while w not in roots:\n",
    "            w_list = list(T.predecessors(w))\n",
    "            random.shuffle(w_list)\n",
    "            w = w_list[0]\n",
    "        d[v] = w    \n",
    "        \n",
    "for i in tqdm(range(len(index_1root))):\n",
    "    i = index_1root[i]\n",
    "    cc = T2_cc[i]\n",
    "    cc_root = list(cc.intersection(roots))[0]\n",
    "    d.update({cc_root:cc_root})\n",
    "    cc_noroots = list(cc - set(cc_roots))\n",
    "    d.update(dict(zip(cc_noroots,[cc_root]*len(cc_noroots))))\n",
    "    \n",
    "inst_id_name_dict = works_authorships_all[['institution_id','institution_name']].drop_duplicates(['institution_id','institution_name']).set_index('institution_id').to_dict()['institution_name']\n",
    "my_file = \"inst_id_name_dict.pickle\"\n",
    "pickle.dump(inst_id_name_dict, open(os.path.join(basepath3, my_file), 'wb')) \n",
    "\n",
    "#missing affiliations #isolated #no parents or childs\n",
    "missing_aff = list(set(inst_id_name_dict.keys()) - set(d.keys()))\n",
    "d.update(dict(zip(missing_aff,missing_aff)))\n",
    "my_file = \"inst_root_map.pickle\"\n",
    "pickle.dump(d, open(os.path.join(basepath3, my_file), 'wb')) \n",
    "\n",
    "#example IU: 592451, 4210119109, 4210101670"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77cab33-8422-43a7-aa0e-e3c6c877b7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file = \"inst_root_map.pickle\"\n",
    "with open(os.path.join(basepath3, my_file),\"rb\") as fp:\n",
    "    d = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6f5579-29b2-42f1-bf84-54668b8bc5be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df37e164-753f-4a0e-b89e-d61755086636",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "works_authorships_all['institution_id'] = works_authorships_all['institution_id'].map(d)\n",
    "#restrict to preprints' authors \n",
    "preprint_author_id_set = set(works_authorships.author_id)\n",
    "my_file = \"preprint_author_id_set.pickle\"\n",
    "pickle.dump(preprint_author_id_set, open(os.path.join(basepath3, my_file), 'wb'))\n",
    "print(f'{len(preprint_author_id_set)} authors preprints')\n",
    "works_authorships_inst = works_authorships_all.query('author_id.isin(@preprint_author_id_set)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2a39f7-2e22-47f9-b3e8-6ce459731065",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#add publication year\n",
    "#works = read_parquet(basepath3 / 'works')\n",
    "works_all = read_parquet(basepath3 / 'works_all')\n",
    "works_all = works_all.reset_index()[['work_id','publication_date_1']]\n",
    "works_all['publication_year'] = works_all['publication_date_1'].dt.year\n",
    "works_all = works_all[['work_id','publication_year']]\n",
    "works_authorships_inst = works_authorships_inst.merge(works_all.reset_index(),on='work_id')\n",
    "works_authorships_inst = works_authorships_inst.drop(columns='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98928cd7-a2a2-41cd-8802-94a2c27a0a48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#save\n",
    "my_file = 'works_authorships_inst2'\n",
    "works_authorships_inst.to_parquet(os.path.join(basepath3, my_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d012f9e2-937b-4bca-a511-ac09926a5f93",
   "metadata": {},
   "source": [
    "### frequency - one inst\n",
    "\n",
    "Keep most frequent institutions each year - no multiple affiliations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d3c662-04d8-458d-992a-f04c625462a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_file = 'works_authorships_inst2'\n",
    "works_authorships_inst = read_parquet(basepath3 / my_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e933a51c-a2bb-48b2-bfad-c00ae443fb4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "focal_authors_ids = preprint_author_id_set\n",
    "works_authors_df = works_authorships_inst\n",
    "persist_absolute=1.0\n",
    "persist_rate=0.3\n",
    "\n",
    "venue = 'institution_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8d3363-b485-431d-b924-c4c5ca1c9e60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for each author, find the list of institutions\n",
    "# keep only authors with at least 2 institutions\n",
    "print('  for each author, find the list of '+venue+'; keep only authors with at least 2 '+venue)\n",
    "authors_with_at_least_2_vanues = (\n",
    "    works_authors_df[\n",
    "        works_authors_df['author_id'].isin(set(focal_authors_ids)) #only the focal_authors\n",
    "    ]\n",
    "    .groupby(by='author_id',sort=False)\n",
    "    .agg(\n",
    "        n_venues=(venue,'nunique')\n",
    "    )\n",
    "    .query('n_venues>=2')\n",
    ")\n",
    "\n",
    "#otherwise that institutions always\n",
    "authors_with_1_vanues = focal_authors_ids - set(authors_with_at_least_2_vanues.index)\n",
    "\n",
    "print(f'{len(focal_authors_ids)} total authors: {len(authors_with_1_vanues)} 1-venue, {len(authors_with_at_least_2_vanues)} more venues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1f4d24-bf2a-4fd1-8ec5-26388d8a65e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_file = \"authors_with_at_least_2_vanues.pickle\"\n",
    "pickle.dump(set(authors_with_at_least_2_vanues.index), open(os.path.join(basepath3, my_file), 'wb')) \n",
    "my_file = \"authors_with_1_vanues.pickle\"\n",
    "pickle.dump(set(authors_with_1_vanues), open(os.path.join(basepath3, my_file), 'wb')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e801090d-b6f1-493e-b248-451aeffdaa85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6c8c80-8beb-45d2-ad20-dc2c6aad4b91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('  Building the lists of '+venue+' per year')\n",
    "works_authors_df = works_authors_df.sort_values(by=['author_id','publication_year'])\n",
    "authors_vanues = (\n",
    "    works_authors_df[\n",
    "            works_authors_df['author_id'].isin(set(authors_with_at_least_2_vanues.index)) #only the focal_authors\n",
    "        ]\n",
    "    .groupby(by=['author_id','publication_year'], as_index=False)  # check the groupby, considering author_id, publication_date and also work_id\n",
    "    #.groupby(by=['author_id','publication_year'], sort=True, as_index=False)  # check the groupby, considering author_id, publication_date and also work_id\n",
    "    .agg(\n",
    "        #vanues=(venue,list), \n",
    "        #num_works=('work_id','nunique'),\n",
    "        most_common_vanues=(venue, lambda x: x.mode().tolist()), #.mode() value that appears most often #there can be multiple [1, 2. 3]\n",
    "        frequency_rate=(venue, lambda x: x.value_counts(normalize=True).values[0]), #percentage max [0.33]\n",
    "        frequency_absolute=(venue, lambda x: x.value_counts().values.tolist()[:2]), #number papers each institution [1,1] #first two\n",
    "        author_name=('author_name', 'first'),\n",
    "    )\n",
    ")\n",
    "\n",
    "my_file = 'authors_vanues'\n",
    "authors_vanues.to_parquet(os.path.join(basepath3, my_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066aaf12-eba6-4837-9132-e63949e8056e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "authors_vanues = read_parquet(basepath3 / 'authors_vanues')\n",
    "print('  Checking for ties')\n",
    "authors_vanues['tie'] = authors_vanues['frequency_absolute'].apply(lambda x: x[0] == x[1] if len(x)!=1 else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afa42d7-4411-4e95-a947-f476bfb72494",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77ad2a4-aeb4-45bd-a1f2-74581dde6dcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_ties(df_):\n",
    "    output_df = pd.DataFrame(columns=['publication_year','most_common_vanue'])\n",
    "\n",
    "    most_common_vanue = []\n",
    "    most_common_vanue.append(df_.iloc[0]['most_common_vanues'][0])    \n",
    "    \n",
    "    # if the first record is a tie, get the next country of affiliation (if len(df_)>1)\n",
    "    if(df_.iloc[0]['tie']):\n",
    "        if(len(df_)>1):\n",
    "            most_common_vanue[0] = df_.iloc[1]['most_common_vanues'][0]\n",
    "\n",
    "    for i in range(1,len(df_)):\n",
    "        #print(f\"{df_2.iloc[i-1]['most_common_country']=},  {df_2.iloc[i]['most_common_country']=}\")\n",
    "        \n",
    "        if(df_.iloc[i]['tie']):\n",
    "            if(most_common_vanue[i-1] in df_.iloc[i]['most_common_vanues']):\n",
    "                most_common_vanue.append(most_common_vanue[i-1])\n",
    "            else:\n",
    "                most_common_vanue.append(df_.iloc[i]['most_common_vanues'][0])\n",
    "        else:\n",
    "            most_common_vanue.append(df_.iloc[i]['most_common_vanues'][0])\n",
    "    \n",
    "    output_df['most_common_vanues'] = most_common_vanue\n",
    "    output_df['publication_year'] = df_['publication_year'].values\n",
    "    \n",
    "    return output_df\n",
    "\n",
    "print('  Solving ties')\n",
    "authors_vanues['most_common_vanues'] = (\n",
    "    authors_vanues\n",
    "    .groupby(by=['author_id'],sort=False)\n",
    "    .apply(\n",
    "        lambda df_: check_ties(df_)\n",
    "    )[['most_common_vanues']]\n",
    "    .values\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "my_file = 'authors_vanues2'\n",
    "authors_vanues.to_parquet(os.path.join(basepath3, my_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c29e9dd-874a-4ad3-bd7a-4a8658c1d6dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_ties(df_):\n",
    "    output_df = pd.DataFrame(columns=['publication_year','most_common_vanue'])\n",
    "\n",
    "    most_common_vanue = []\n",
    "    most_common_vanue.append(df_.iloc[0]['most_common_vanues'][0])    \n",
    "    \n",
    "    # if the first record is a tie, get the next country of affiliation (if len(df_)>1)\n",
    "    if(df_.iloc[0]['tie']):\n",
    "        if(len(df_)>1):\n",
    "            most_common_vanue[0] = df_.iloc[1]['most_common_vanues'][0]\n",
    "\n",
    "    for i in range(1,len(df_)):\n",
    "        #print(f\"{df_2.iloc[i-1]['most_common_country']=},  {df_2.iloc[i]['most_common_country']=}\")\n",
    "        \n",
    "        if(df_.iloc[i]['tie']):\n",
    "            if(most_common_vanue[i-1] in df_.iloc[i]['most_common_vanues']):\n",
    "                most_common_vanue.append(most_common_vanue[i-1])\n",
    "            else:\n",
    "                most_common_vanue.append(df_.iloc[i]['most_common_vanues'][0])\n",
    "        else:\n",
    "            most_common_vanue.append(df_.iloc[i]['most_common_vanues'][0])\n",
    "    \n",
    "    output_df['most_common_vanues'] = most_common_vanue\n",
    "    output_df['publication_year'] = df_['publication_year'].values\n",
    "    \n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da47521-5a83-461c-93f9-e480b2d180d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "authors_vanues2 = read_parquet(basepath3 / 'authors_vanues2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eb9dfb-4a66-4025-a7d4-59d504196c31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "authors_vanues['frequency_absolute'] = authors_vanues['frequency_absolute'].apply(lambda x: x[0])\n",
    "# removing rows where frequency is less than persist\n",
    "print('  Removing rows where frequency is less than a minimum threshold')\n",
    "authors_vanues = (\n",
    "    authors_vanues[\n",
    "        (authors_vanues['frequency_absolute']>=persist_absolute) &\n",
    "        (authors_vanues['frequency_rate']>=persist_rate)\n",
    "    ]\n",
    ")\n",
    "my_file = 'authors_vanues3'\n",
    "authors_vanues.to_parquet(os.path.join(basepath3, my_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a75078-5296-4695-a1d9-6afe9c689439",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e4d4df-77a0-4489-a672-c19a4cef4c86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "authors_vanues = read_parquet(basepath3 / 'authors_vanues3')\n",
    "my_file = \"authors_with_at_least_2_vanues.pickle\"\n",
    "with open(os.path.join(basepath3, my_file),\"rb\") as fp:\n",
    "    authors_with_at_least_2_vanues = pickle.load(fp)\n",
    "my_file = \"authors_with_1_vanues.pickle\"\n",
    "with open(os.path.join(basepath3, my_file),\"rb\") as fp:\n",
    "    authors_with_1_vanues = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74023792-6b17-44b0-a40f-d011eec49286",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "authors_vanues = authors_vanues[['author_id','publication_year','most_common_vanues']]\n",
    "authors_vanues['most_common_vanues'] = authors_vanues['most_common_vanues'].apply(lambda x: x[0])\n",
    "authors_vanues = authors_vanues.rename(columns={'most_common_vanues':'institution_id'})\n",
    "\n",
    "authors_vanues2 = works_authors_df[works_authors_df['author_id'].isin(set(authors_with_1_vanues))]\n",
    "authors_vanues2 = authors_vanues2[['author_id','publication_year','institution_id']].drop_duplicates(['author_id','publication_year']).sort_values(by=['author_id','publication_year'])\n",
    "\n",
    "authors_vanues_final = pd.concat([authors_vanues,authors_vanues2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d08291-91fc-4439-b849-b202d4ad2f4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_file = 'authors_vanues_final'\n",
    "authors_vanues_final.to_parquet(os.path.join(basepath3, my_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302c177d-b8f8-4300-8771-95660d626f0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db140f25-e10f-4fdb-b7a9-74951c8ab37b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#add affiliations to works_authors table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6ccba2-2f22-4287-a433-d19507cb013a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "authors_vanues_final = read_parquet(basepath3 / 'authors_vanues_final')\n",
    "works_authorships = read_parquet(basepath / 'works_authorships')\n",
    "works_authorships = works_authorships[['work_id','publication_year','author_id','author_name']]\n",
    "works_authorships = works_authorships.drop_duplicates(['work_id','author_id'])\n",
    "works = read_parquet(basepath3 / 'works')\n",
    "works_authorships = works_authorships.merge(works.reset_index(),on='work_id').set_index('publication_date_1').reset_index()\n",
    "\n",
    "author_id_set = authors_vanues_final['author_id'].unique()\n",
    "years_set = np.arange(authors_vanues_final.publication_year.min(), authors_vanues_final.publication_year.max() + 1)\n",
    "idx = pd.MultiIndex.from_product((years_set, author_id_set), names=['publication_year', 'author_id'])\n",
    "authors_vanues_final = authors_vanues_final.set_index(['publication_year', 'author_id']).reindex(idx, fill_value=np.nan).reset_index()\n",
    "\n",
    "#fill-in #if nan take the previous one #if no one - take the next one\n",
    "authors_vanues_final = authors_vanues_final.sort_values(by=['author_id','publication_year'])\n",
    "authors_vanues_final['institution_id'] = authors_vanues_final.groupby('author_id').institution_id.ffill()\n",
    "authors_vanues_final['institution_id'] = authors_vanues_final.groupby('author_id').institution_id.bfill()\n",
    "\n",
    "authors_vanues_final = authors_vanues_final[authors_vanues_final.institution_id.notnull()]\n",
    "authors_vanues_final['institution_id'] = authors_vanues_final['institution_id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6886e0-a9a0-45c0-92fb-4458dadec8a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "702e5cd6-16c6-430c-879f-f7e0e9f7e34b",
   "metadata": {},
   "source": [
    "### city, country, continent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4980a9fb-1c94-4cf3-990f-ba9f79f99286",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#add: institution name, city, country, continent\n",
    "my_file = \"inst_id_name_dict.pickle\"\n",
    "with open(os.path.join(basepath3, my_file),\"rb\") as fp:\n",
    "    inst_id_name_dict = pickle.load(fp)\n",
    "authors_vanues_final['institution_name'] = authors_vanues_final['institution_id'].map(inst_id_name_dict)\n",
    "\n",
    "#add country (no city)\n",
    "institutions_geo_df = pd.read_csv(basepath4 / 'institutions_geo.csv.gz')\n",
    "#fillin missing info\n",
    "institutions_geo_df.loc[institutions_geo_df['country']=='Namibia', 'country_code'] = 'NA' #University of Namibia\n",
    "inst_geo_dict = institutions_geo_df[['country_code','country']].dropna().drop_duplicates(['country_code','country']).set_index('country_code').to_dict()['country']\n",
    "institutions_geo_df['country'] = institutions_geo_df['country_code'].map(inst_geo_dict)\n",
    "inst_geo_dict = institutions_geo_df[['city','country']].dropna().drop_duplicates(['city','country'],keep='last').set_index('city').to_dict()['country']\n",
    "institutions_geo_df.loc[institutions_geo_df.country.isna(),'country'] = institutions_geo_df.loc[institutions_geo_df.country.isna(),'city'].map(inst_geo_dict)\n",
    "inst_geo_dict = institutions_geo_df[['country','country_code']].dropna().drop_duplicates(['country','country_code']).set_index('country').to_dict()['country_code']\n",
    "institutions_geo_df['country_code'] = institutions_geo_df['country'].map(inst_geo_dict)\n",
    "institutions_geo_df.loc[institutions_geo_df['institution_id']==194744927,'country_code'] = 'SG'\n",
    "institutions_geo_df.loc[institutions_geo_df['institution_id']==194744927,'country'] = 'Singapore'\n",
    "institutions_geo_df.loc[institutions_geo_df['institution_id']==142504963,'country_code'] = 'IN'\n",
    "institutions_geo_df.loc[institutions_geo_df['institution_id']==142504963,'country'] = 'India'\n",
    "institutions_geo_df.loc[institutions_geo_df['institution_id']==4387155609,'country_code'] = 'FR'\n",
    "institutions_geo_df.loc[institutions_geo_df['institution_id']==4387155609,'country'] = 'France'\n",
    "\n",
    "authors_vanues_final = authors_vanues_final.merge(institutions_geo_df[['institution_id','country_code','country']],on='institution_id',how='left')\n",
    "\n",
    "authors_vanues_final.loc[authors_vanues_final['institution_id']==4387152698,'country_code'] = 'IE'\n",
    "authors_vanues_final.loc[authors_vanues_final['institution_id']==4387152698,'country'] = 'Ireland'\n",
    "authors_vanues_final.loc[authors_vanues_final['institution_id']==4387152931,'country_code'] = 'JP'\n",
    "authors_vanues_final.loc[authors_vanues_final['institution_id']==4387152931,'country'] = 'Japan'\n",
    "authors_vanues_final.loc[authors_vanues_final['institution_id']==4387152970,'country_code'] = 'IN'\n",
    "authors_vanues_final.loc[authors_vanues_final['institution_id']==4387152970,'country'] = 'India'\n",
    "authors_vanues_final.loc[authors_vanues_final['institution_id']==4387153060,'country_code'] = 'KE'\n",
    "authors_vanues_final.loc[authors_vanues_final['institution_id']==4387153060,'country'] = 'Kenya'\n",
    "authors_vanues_final.loc[authors_vanues_final['institution_id']==4387153083,'country_code'] = 'IN'\n",
    "authors_vanues_final.loc[authors_vanues_final['institution_id']==4387153083,'country'] = 'India'\n",
    "authors_vanues_final.loc[authors_vanues_final['institution_id']==4387153738,'country_code'] = 'IN'\n",
    "authors_vanues_final.loc[authors_vanues_final['institution_id']==4387153738,'country'] = 'India'\n",
    "authors_vanues_final.loc[authors_vanues_final['institution_id']==4387154466,'country_code'] = 'IN'\n",
    "authors_vanues_final.loc[authors_vanues_final['institution_id']==4387154466,'country'] = 'India'\n",
    "authors_vanues_final.loc[authors_vanues_final['institution_id']==4387154815,'country_code'] = 'NP'\n",
    "authors_vanues_final.loc[authors_vanues_final['institution_id']==4387154815,'country'] = 'Nepal'\n",
    "authors_vanues_final.loc[authors_vanues_final['institution_id']==4387154860,'country_code'] = 'IN'\n",
    "authors_vanues_final.loc[authors_vanues_final['institution_id']==4387154860,'country'] = 'India'\n",
    "authors_vanues_final.loc[authors_vanues_final['institution_id']==4387155965,'country_code'] = 'IN'\n",
    "authors_vanues_final.loc[authors_vanues_final['institution_id']==4387155965,'country'] = 'India'\n",
    "authors_vanues_final.loc[authors_vanues_final['institution_id']==4387156305,'country_code'] = 'NP'\n",
    "authors_vanues_final.loc[authors_vanues_final['institution_id']==4387156305,'country'] = 'Nepal'\n",
    "authors_vanues_final.loc[authors_vanues_final['institution_id']==4391012538,'country_code'] = 'PK'\n",
    "authors_vanues_final.loc[authors_vanues_final['institution_id']==4391012538,'country'] = 'Pakistan'\n",
    "authors_vanues_final.loc[authors_vanues_final['institution_id']==4392738202,'country_code'] = 'IN'\n",
    "authors_vanues_final.loc[authors_vanues_final['institution_id']==4392738202,'country'] = 'India'\n",
    "authors_vanues_final.loc[authors_vanues_final['institution_id']==4396570495,'country_code'] = 'JO'\n",
    "authors_vanues_final.loc[authors_vanues_final['institution_id']==4396570495,'country'] = 'Jordan'\n",
    "authors_vanues_final.loc[authors_vanues_final['institution_id']==4396570510,'country_code'] = 'NP'\n",
    "authors_vanues_final.loc[authors_vanues_final['institution_id']==4396570510,'country'] = 'Nepal'\n",
    "authors_vanues_final.loc[authors_vanues_final['institution_id']==4399657981,'country_code'] = 'IN'\n",
    "authors_vanues_final.loc[authors_vanues_final['institution_id']==4399657981,'country'] = 'India'\n",
    "authors_vanues_final.loc[authors_vanues_final['institution_id']==4400008961,'country_code'] = 'GH'\n",
    "authors_vanues_final.loc[authors_vanues_final['institution_id']==4400008961,'country'] = 'Ghana'\n",
    "authors_vanues_final.loc[authors_vanues_final['institution_id']==4400009046,'country_code'] = 'IN'\n",
    "authors_vanues_final.loc[authors_vanues_final['institution_id']==4400009046,'country'] = 'India'\n",
    "authors_vanues_final.loc[authors_vanues_final['institution_id']==4400573231,'country_code'] = 'GH'\n",
    "authors_vanues_final.loc[authors_vanues_final['institution_id']==4400573231,'country'] = 'Ghana'\n",
    "authors_vanues_final.loc[authors_vanues_final['institution_id']==4400573235,'country_code'] = 'GH'\n",
    "authors_vanues_final.loc[authors_vanues_final['institution_id']==4400573235,'country'] = 'Ghana'\n",
    "authors_vanues_final.loc[authors_vanues_final['institution_id']==4402554220,'country_code'] = 'IN'\n",
    "authors_vanues_final.loc[authors_vanues_final['institution_id']==4402554220,'country'] = 'India'\n",
    "authors_vanues_final.loc[authors_vanues_final['institution_id']==4403386676,'country_code'] = 'CN'\n",
    "authors_vanues_final.loc[authors_vanues_final['institution_id']==4403386676,'country'] = 'China'\n",
    "authors_vanues_final.loc[authors_vanues_final['institution_id']==4403928290,'country_code'] = 'BD'\n",
    "authors_vanues_final.loc[authors_vanues_final['institution_id']==4403928290,'country'] = 'Bangladesh'\n",
    "authors_vanues_final.loc[authors_vanues_final['institution_id']==4210144721,'country_code'] = 'US'\n",
    "authors_vanues_final.loc[authors_vanues_final['institution_id']==4210144721,'country'] = 'United States'\n",
    "authors_vanues_final.loc[authors_vanues_final['institution_id']==4403928291,'country_code'] = 'FR'\n",
    "authors_vanues_final.loc[authors_vanues_final['institution_id']==4403928291,'country'] = 'France'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e585a6d4-9fa8-44e1-91f7-baa2bc2b8015",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "missing_inst_country = list(set(authors_vanues_final[authors_vanues_final.country.isna()].institution_id))\n",
    "print(len(missing_inst_country))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1676a6-d075-4811-a821-2a38b4e8fba6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "url=\"https://api.openalex.org/institutions/I\"\n",
    "missing_inst_country_dict = {}\n",
    "for i in tqdm(missing_inst_country):\n",
    "    url_i = url+str(i) \n",
    "    response = requests.get(url_i)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if data['geo']['country'] is not None:\n",
    "            missing_inst_country_dict[i] = data['geo']['country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c572e57-caeb-4a6c-8337-90035e9affe9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in tqdm(list(missing_inst_country_dict.keys())):\n",
    "    authors_vanues_final.loc[authors_vanues_final.institution_id==i,'country'] = missing_inst_country_dict[i] \n",
    "    authors_vanues_final.loc[authors_vanues_final.institution_id==i,'country_code'] = authors_vanues_final.loc[authors_vanues_final.institution_id==i,'country'].map(inst_geo_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ec3436-1169-4445-91c2-e16f4f438b1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#add continent\n",
    "#assign continent to country \n",
    "import pycountry_convert as pc\n",
    "\n",
    "authors_vanues_final['country_code'] = authors_vanues_final['country_code'].replace({'VA': 'IT'})\n",
    "authors_vanues_final['country'] = authors_vanues_final['country'].replace({'Vatican': 'Italy'})\n",
    "authors_vanues_final['country_code'] = authors_vanues_final['country_code'].replace({'SX': 'NL'})\n",
    "authors_vanues_final['country'] = authors_vanues_final['country'].replace({'Sint Maarten': 'Netherlands'})\n",
    "authors_vanues_final['country_code'] = authors_vanues_final['country_code'].replace({'TL': 'ID'})\n",
    "authors_vanues_final['country'] = authors_vanues_final['country'].replace({'Timor Leste': 'Indonesia'})\n",
    "\n",
    "def country_to_continent(country_code):\n",
    "    return pc.country_alpha2_to_continent_code(country_code)\n",
    "authors_vanues_final['continent_code'] = authors_vanues_final['country_code'].apply(lambda x: country_to_continent(x))\n",
    "def continent_to_continent(continent_code):\n",
    "    return  pc.convert_continent_code_to_continent_name(continent_code)\n",
    "authors_vanues_final['continent'] = authors_vanues_final['continent_code'].apply(lambda x: continent_to_continent(x))\n",
    "\n",
    "my_file = 'authors_vanues_final_fill'\n",
    "authors_vanues_final.to_parquet(os.path.join(basepath3, my_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98c79df-e12d-44d2-9a17-0fe86e77dec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b09bf0f1-946d-4218-97b9-cfb1f741a3cb",
   "metadata": {},
   "source": [
    "### merge with works_authorships table\n",
    "\n",
    "merge with works_authors table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e59420-dfb5-49b3-997b-da3ab4852e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "works_authorships = read_parquet(basepath / 'works_authorships')\n",
    "works_authorships['author_id'] = works_authorships['author_id'].astype(int)\n",
    "#set preprints with at least one nan\n",
    "print(f'Delate all preprints with not full affiliation info (not fillin): lose {(len(set(works_authorships[works_authorships.institution_id.isna()].work_id))/len(set(works_authorships.work_id)))*100:.2f}%')\n",
    "works_authorships = works_authorships[['work_id','author_id','author_name','publication_year']]\n",
    "#works_authorships['publication_year'] = works_authorships['publication_year'].astype(int)\n",
    "authors_vanues_final = read_parquet(basepath3 / 'authors_vanues_final_fill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d75b58-4d80-4cdc-8db9-0b6400beb425",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f'{(len(works_authorships[works_authorships.institution_id.isna()])/len(works_authorships))*100:.2f}% nan institution rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7854ff36-65a8-4eca-8f2b-95610c153e58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#delate all preprints with not full affiliation info\n",
    "print(f'Delate all preprints with not full affiliation info: lose {100*len(set(works_authorships[works_authorships.institution_id.isna()].work_id))/len(set(works_authorships.work_id)):.2f}% of works')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cd699b-0add-4107-9be1-9ce88c8e443a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#delate only rows with missing institutions info\n",
    "print(f'Delate only rows with missing institutions info: lose {100 - (100*len(set(works_authorships[works_authorships.institution_id.notnull()].work_id))/len(set(works_authorships.work_id))):.2f}% of works')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1946bb-5b77-474f-b35b-6e2755baa55a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#works_authorships = works_authorships[works_authorships.institution_id.notnull()]\n",
    "works_missinginfo = set(works_authorships[works_authorships.institution_id.isna()].work_id)\n",
    "works_authorships = works_authorships[~works_authorships.work_id.isin(works_missinginfo)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1457195-b894-4621-ade6-9f3e04bb4b45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##add publication date\n",
    "works = read_parquet(basepath3 / 'works')\n",
    "works_authorships = works_authorships.merge(works.reset_index()[['work_id','publication_date_1']].reset_index(),on='work_id')\n",
    "works_authorships = works_authorships.drop_duplicates(['work_id','author_id'])\n",
    "works_authorships['author_id'] = works_authorships['author_id'].astype(int)\n",
    "works_authorships['institution_id'] = works_authorships['institution_id'].astype(int)\n",
    "works_authorships = works_authorships.sort_values(by=['publication_date_1','work_id'])\n",
    "works_authorships = works_authorships.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6151713-eec9-4ba9-a358-5a3a58d2a6f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_file = \"preprint_work_id_set.pickle\"\n",
    "with open(os.path.join(basepath3, my_file),\"rb\") as fp:\n",
    "    preprint_work_id_set = pickle.load(fp)\n",
    "print(f'{len(preprint_work_id_set) - len(set(works_authorships.work_id))} lost preprints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8667f673-2ff5-4c65-aee3-dcd311155a38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#time period\n",
    "works_authorships = works_authorships.query(\"publication_date_1 >= '2000-01-01'\").query(\"publication_date_1 <= '2024-12-01'\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29987a3e-6f89-41ab-af78-bffbf394b3e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#save\n",
    "my_file = 'works_authorships1'\n",
    "works_authorships.to_parquet(os.path.join(basepath3, my_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c505b4-1194-4205-9093-3344db6fad48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19150de4-3334-4ac1-a9be-d81a515cc3f7",
   "metadata": {},
   "source": [
    "### institutions distance\n",
    "\n",
    "* Calculate distances\n",
    "* Threshold 1 km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43055d32-65a1-4731-a91d-8dc168b70e23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#too many institutions - calculate distance only if edge in institution collaboration graphs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc83a14d-068d-456d-bba7-7a06d817db3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "works_authorships = read_parquet(basepath3 / 'works_authorships1')\n",
    "works_authorships = works_authorships.set_index('publication_date_1')\n",
    "institutions_set = set(works_authorships.institution_id)\n",
    "print(f'{len(institutions_set)} institutions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dc8a11-abd9-4227-8e8f-2f9ed430d054",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "institutions_geo_df = pd.read_csv(basepath4 / 'institutions_geo.csv.gz')\n",
    "institutions_set_geo = set(institutions_geo_df.institution_id)\n",
    "print(f'{len(institutions_set_geo)} institutions')\n",
    "institutions_geo_df = institutions_geo_df.query('institution_id.isin(@institutions_set)')\n",
    "print(f'{len(set(institutions_geo_df.institution_id))} institutions')\n",
    "institutions_geo_df['location'] = list(zip(institutions_geo_df.latitude, institutions_geo_df.longitude))\n",
    "institutions_geo_map = dict(zip(institutions_geo_df['institution_id'],institutions_geo_df['location']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76ca05f-2d74-4215-abd5-aae98ed41f05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "missing_inst_geo_map = set(works_authorships.institution_id) - set(institutions_geo_df.institution_id)\n",
    "url=\"https://api.openalex.org/institutions/I\"\n",
    "missing_inst_country_dict = {}\n",
    "for i in tqdm(missing_inst_geo_map):\n",
    "    url_i = url+str(i) \n",
    "    response = requests.get(url_i)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if (data['geo']['latitude'] is not None) and (data['geo']['longitude'] is not None):\n",
    "            institutions_geo_map[i] = (data['geo']['latitude'],data['geo']['longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131d157c-89e4-460c-b4cc-d830aaa9286f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import geopy.distance\n",
    "def make_institution_graph(works_authors_rows):\n",
    "    \n",
    "    institution_id_set = set(works_authors_rows.institution_id)\n",
    "                                  \n",
    "    bip_g = nx.from_pandas_edgelist(\n",
    "        works_authors_rows,\n",
    "        source='work_id', target='institution_id'\n",
    "    )\n",
    "   \n",
    "    inst_graph = nx.bipartite.projected_graph(bip_g,nodes=institution_id_set) \n",
    "\n",
    "    return inst_graph\n",
    "I = make_institution_graph(works_authors_rows = works_authorships[['work_id','institution_id']].drop_duplicates(['work_id','institution_id']))\n",
    "I_dist = nx.to_pandas_edgelist(I)\n",
    "I_dist['source_loc'] = I_dist['source'].map(institutions_geo_map)\n",
    "I_dist['target_loc'] = I_dist['target'].map(institutions_geo_map)\n",
    "I_dist['dist'] = I_dist.apply(lambda x : geopy.distance.distance(x.source_loc,x.target_loc).km ,axis=1) #faster: distance.great_circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3592ff07-2651-4db8-890a-d490d38fa46e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb8202f-99b2-4a0a-bc11-6f1ff15f9b73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "I_dist = I_dist[['source','target','dist']]\n",
    "I_dist = pd.concat([I_dist,I_dist[['target','source','dist']].rename(columns={'source':'target','target':'source'})]) #order nodes\n",
    "I_dist = I_dist.drop_duplicates(['target','source'])\n",
    "## add same institution-loops 0 dist\n",
    "I_dist = pd.concat([I_dist,pd.DataFrame.from_dict({'source':list(institutions_set),'target':list(institutions_set),'dist':[0]*len(institutions_set)})])\n",
    "my_file = 'I_dist'\n",
    "I_dist.to_parquet(os.path.join(basepath3, my_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0cc179-54b0-4e67-9275-a3e571e11a3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be01322-3d82-4fbc-8287-279dcaa0116c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Def insts same if dist<1km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214d6cd2-8dd5-4cc6-9e7c-5d60d838f6b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "I_dist = pd.read_parquet( basepath3 /  \"I_dist\"  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec1ab0f-e13e-4027-b981-638fb4a841d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "I_dist = pd.read_parquet( basepath3 /  \"I_dist\"  ) \n",
    "I_dist['source'] = I_dist['source'].astype(int)\n",
    "I_dist['target'] = I_dist['target'].astype(int)\n",
    "I_set = (set(I_dist['source'])).union(set(I_dist['target'])) \n",
    "swap = I_dist['source'] < I_dist['target'] #drop duplicates edges\n",
    "I_dist.loc[swap, ['source', 'target']] = I_dist.loc[swap, ['target', 'source']].values\n",
    "I_dist = I_dist.drop_duplicates(subset=['source', 'target'])\n",
    "I_dist0 = I_dist[I_dist.dist<1]\n",
    "print(f'{(len(I_dist0)/len(I_dist))*100:.2f}% inst dist 0')\n",
    "I_dist0_intra = I_dist0[I_dist0.source==I_dist0.target]\n",
    "I_dist0_inter = I_dist0[I_dist0.source!=I_dist0.target]\n",
    "print(f'{(len(I_dist0_intra)/len(I_dist))*100:.2f}% inst intra, {(len(I_dist0_inter)/len(I_dist))*100:.2f}% inst inter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5aae73-4983-4fac-a2b5-94359b643163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7775126-56f6-4d0c-8c17-f4e168bc6879",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "I_dist = pd.read_parquet( basepath3 /  \"I_dist\"  ) \n",
    "I_dist.loc[I_dist['dist'] < 1, 'dist'] = 0\n",
    "I_dist['intra'] = 0\n",
    "#I_dist.loc[I_dist.source==I_dist.target,'intra'] = 1\n",
    "I_dist.loc[I_dist.dist==0,'intra'] = 1\n",
    "my_file = 'I_dist_threshold'\n",
    "I_dist.to_parquet(os.path.join(basepath3, my_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e861a69b-f629-49b3-850e-606c0a513a53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "works_authorships = works_authorships.drop(columns='index')\n",
    "my_file = 'works_authors_aff'\n",
    "works_authorships.to_parquet(os.path.join(basepath3, my_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5b3f19-ba56-45cc-b51c-5963570487b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2bca7df2-aea2-439d-9333-1e94a63b9565",
   "metadata": {},
   "source": [
    "### number of authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee413fd-56ad-47d9-8e9a-ae89cdb2bd51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#preprint with at least one author - restrict tables to them\n",
    "#works_authorships_drop = works_authorships.drop_duplicates(['work_id','author_id'])\n",
    "works_authors_aff = read_parquet(basepath3 / 'works_authors_aff')\n",
    "num_auhors_df = works_authors_aff.groupby('work_id').author_id.count().to_frame().reset_index().rename(columns={'author_id':'num_authors'})                                  \n",
    "my_file = 'num_auhors_df'\n",
    "num_auhors_df.to_parquet(os.path.join(basepath3, my_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f1d60f-b5b7-4d9c-a492-2e04d8d34ee3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_auhors_df = read_parquet(basepath3 / 'num_auhors_df')\n",
    "works = read_parquet(basepath3 / 'works')\n",
    "works = works.reset_index().merge(num_auhors_df,on='work_id').set_index('publication_date_1')\n",
    "my_file = 'works2'\n",
    "works.to_parquet(os.path.join(basepath3, my_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72a4dbc-4622-4af7-b06c-04c038fdeb2b",
   "metadata": {},
   "source": [
    "### solo preprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260fd225-2067-4023-af81-21e15d7c7ea8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_auhors_df = read_parquet(basepath3 / 'num_auhors_df')\n",
    "preprint_id_set_solo = set(num_auhors_df[num_auhors_df.num_authors == 1].work_id)\n",
    "preprint_id_set_nosolo = set(num_auhors_df[num_auhors_df.num_authors > 1].work_id)\n",
    "my_file = \"preprint_id_set_solo.pickle\"\n",
    "pickle.dump(preprint_id_set_solo, open(os.path.join(basepath3, my_file), 'wb'))\n",
    "my_file = \"preprint_id_set_nosolo.pickle\"\n",
    "pickle.dump(preprint_id_set_nosolo, open(os.path.join(basepath3, my_file), 'wb'))\n",
    "print(f'{(len(preprint_id_set_solo)/len(num_auhors_df))*100:.2f}% solo preprints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e6f99a-7cea-4ac6-8709-a3550f6ea2c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18982bb8-fe8b-4b15-9576-eabbe706a338",
   "metadata": {},
   "source": [
    "## Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26aa524c-e14d-43ed-86de-e651e8a9fc9e",
   "metadata": {},
   "source": [
    "### level 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c541e6-f72b-40ad-8b67-099ea6f31c3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#preprint\n",
    "works_concepts = pd.read_parquet(os.path.join(basepath, 'works_concepts'), engine='pyarrow')\n",
    "my_file = \"preprint_id_set.pickle\"\n",
    "with open(os.path.join(basepath3, my_file),\"rb\") as fp:\n",
    "    preprint_id_set = pickle.load(fp)\n",
    "works_concepts = works_concepts.query('work_id.isin(@preprint_id_set)') #restrict work ids\n",
    "works_concepts_l1 = works_concepts[works_concepts.level == 1]\n",
    "works_concepts = works_concepts.merge(works.reset_index(),on='work_id')\n",
    "works_concepts = works_concepts[['work_id','publication_date_1','publication_date','concept_id','concept_name','level','score']]\n",
    "works_concepts['level'] = works_concepts['level'].astype(int)\n",
    "my_file = 'works_concepts'\n",
    "works_concepts.to_parquet(os.path.join(basepath3, my_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9027c0-cdf0-4d43-8054-a3969cd86e80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bcde03fd-08ba-45bf-8457-80eab2727296",
   "metadata": {},
   "source": [
    "### COVID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f9a918-6f3e-45f8-89c1-a710cc841359",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#COVID papers: look at openalex concepts\n",
    "COVID_concepts = {3008058167,3006700255,3007834351}\n",
    "works_concepts_COVID = works_concepts.query('concept_id.isin(@COVID_concepts)')\n",
    "preprint_id_set_COVID = set(works_concepts_COVID.work_id)\n",
    "print(f'{len(preprint_id_set_COVID)} papers COVID concepts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7fe4a7-7f75-4299-9cb9-3fe5df7b9972",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#COVID papers: check for word 'COVID' in the title\n",
    "works_ = read_parquet(basepath / 'works')\n",
    "works_ = works_[['title']].reset_index()\n",
    "works_['title'] = works_['title'].astype(str)\n",
    "\n",
    "preprint_id_set_COVIDtitle = set(\n",
    "      works_\n",
    "    .query('title.str.lower().str.contains(\"covid\")')\n",
    "    .work_id\n",
    ")\n",
    "preprint_id_set_COVID = preprint_id_set_COVID.union(preprint_id_set_COVIDtitle)\n",
    "print(f'{len(preprint_id_set_COVIDtitle)} papers COVID word in the title')\n",
    "\n",
    "preprint_id_set_noCOVID = preprint_id_set - preprint_id_set_COVID\n",
    "print(f'{len(preprint_id_set_COVID)} ({(len(preprint_id_set_COVID)/len(preprint_id_set))*100:.2f}%) COVID papers')\n",
    "my_file = 'preprint_id_set_COVID'\n",
    "pickle.dump(preprint_id_set_COVID, open(os.path.join(basepath3, my_file), 'wb'))\n",
    "my_file = 'preprint_id_set_noCOVID'\n",
    "pickle.dump(preprint_id_set_noCOVID, open(os.path.join(basepath3, my_file), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4d3026-b574-4fab-9dff-01fcda256355",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36b22170-5e1a-441a-a7dc-b264f4129c3c",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3496746-d979-4b6c-a706-f67d4dc61cac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "works_referenced_works = read_parquet(basepath / 'works_referenced_works',\n",
    "                                      columns=['work_id', 'referenced_work_id', 'work_publication_date', 'referenced_work_publication_date']\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20235b5-4c5c-4d02-b10d-0dc953272b0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_file = \"preprint_id_set.pickle\"\n",
    "with open(os.path.join(basepath3, my_file),\"rb\") as fp:\n",
    "    preprint_id_set = pickle.load(fp)\n",
    "works2 = read_parquet(basepath3 / 'works2')\n",
    "#works_referenced_works = works_referenced_works.query('work_id.isin(@preprint_id_set)') #restrict work ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e61238-59fd-4ffa-b47e-24b5d97f8f50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "works_month_dict = works2[['work_id']].reset_index().set_index('work_id').to_dict()['publication_date_1']\n",
    "my_file = \"works_month_dict.pickle\"\n",
    "pickle.dump(works_month_dict, open(os.path.join(basepath3, my_file), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f9ed97-d075-4c9a-916d-9bf99431b640",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#preprints right publication_date\n",
    "works_referenced_works.loc[works_referenced_works.work_id.isin(preprint_id_set),'work_publication_date'] = works_referenced_works.loc[works_referenced_works.work_id.isin(preprint_id_set),'work_id'].map(works_month_dict)\n",
    "works_referenced_works.loc[works_referenced_works.referenced_work_id.isin(preprint_id_set),'referenced_work_publication_date'] = works_referenced_works.loc[works_referenced_works.referenced_work_id.isin(preprint_id_set),'referenced_work_id'].map(works_month_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eeb0616-29d2-4638-b090-51b696bf467c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "count_ref_df = works_referenced_works.query('work_id.isin(@preprint_id_set)').groupby('work_id').referenced_work_id.count().to_frame().reset_index().rename(columns={'referenced_work_id':'ref_count'})\n",
    "count_cit_df = works_referenced_works.query('referenced_work_id.isin(@preprint_id_set)').groupby('referenced_work_id').work_id.count().to_frame().reset_index().rename(columns={'work_id':'cit_count','referenced_work_id':'work_id'})\n",
    "\n",
    "preprint_id_set_noref = preprint_id_set - set(count_ref_df.work_id)\n",
    "preprint_id_set_nocit = preprint_id_set - set(count_cit_df.work_id)\n",
    "preprint_id_set_noref_nocit = preprint_id_set_noref.union(preprint_id_set_nocit)\n",
    "print(f'{len(preprint_id_set_noref)/len(preprint_id_set)*100:.2f}% papers no references')\n",
    "print(f'{len(preprint_id_set_nocit)/len(preprint_id_set)*100:.2f}% papers no citations')\n",
    "print(f'{len(preprint_id_set_noref_nocit)/len(preprint_id_set)*100:.2f}% papers no references or no citations')\n",
    "my_file = \"preprint_id_set_noref.pickle\"\n",
    "pickle.dump(preprint_id_set_noref, open(os.path.join(basepath3, my_file), 'wb'))\n",
    "my_file = \"preprint_id_set_nocit.pickle\"\n",
    "pickle.dump(preprint_id_set_nocit, open(os.path.join(basepath3, my_file), 'wb'))\n",
    "\n",
    "#add works zero citations and references\n",
    "count_cit_df = pd.concat([count_cit_df,pd.DataFrame.from_dict({'work_id':list(preprint_id_set_nocit),'cit_count':[0]*len(preprint_id_set_nocit)})])\n",
    "count_ref_df = pd.concat([count_ref_df,pd.DataFrame.from_dict({'work_id':list(preprint_id_set_noref),'ref_count':[np.nan]*len(preprint_id_set_noref)})])\n",
    "my_file = \"count_ref_df.pickle\"\n",
    "pickle.dump(count_ref_df, open(os.path.join(basepath3, my_file), 'wb'))\n",
    "my_file = \"count_cit_df.pickle\"\n",
    "pickle.dump(count_cit_df, open(os.path.join(basepath3, my_file), 'wb'))\n",
    "\n",
    "works3 = works2.reset_index().merge(count_cit_df.merge(count_ref_df,on='work_id'),on='work_id').set_index('publication_date_1')\n",
    "\n",
    "my_file = 'works3'\n",
    "works3.to_parquet(os.path.join(basepath3, my_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f412a1-0a3b-4965-aefe-8fb78dcb0bae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#differences years\n",
    "works_referenced_works['work_publication_date_1'] = pd.to_datetime(pd.DataFrame({'day': 1, \n",
    "                                              'month': works_referenced_works.work_publication_date.dt.month, \n",
    "                                              'year': works_referenced_works.work_publication_date.dt.year},\n",
    "                                              index=works_referenced_works.index))\n",
    "works_referenced_works['referenced_work_publication_date_1'] = pd.to_datetime(pd.DataFrame({'day': 1, \n",
    "                                              'month': works_referenced_works.referenced_work_publication_date.dt.month, \n",
    "                                              'year': works_referenced_works.referenced_work_publication_date.dt.year},\n",
    "                                              index=works_referenced_works.index))\n",
    "\n",
    "works_referenced_works = works_referenced_works.drop(columns=['work_publication_date','referenced_work_publication_date'])\n",
    "\n",
    "works_referenced_works = works_referenced_works[works_referenced_works['work_publication_date_1']> pd.Timestamp(1800, 1, 1)]\n",
    "works_referenced_works = works_referenced_works[works_referenced_works['referenced_work_publication_date_1']> pd.Timestamp(1800, 1, 1)]\n",
    "works_referenced_works['diff_publication_date_1'] = (works_referenced_works['work_publication_date_1'] - works_referenced_works['referenced_work_publication_date_1'])/np.timedelta64(1, 'Y')\n",
    "\n",
    "my_file = 'works_referenced_works'\n",
    "works_referenced_works.to_parquet(os.path.join(basepath3, my_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9a02bb-d5ca-4343-a50e-46892564635e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d624ec8f-a859-43e4-802f-8bf15558c6ac",
   "metadata": {},
   "source": [
    "## Save final tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86d2c50-87bc-48c7-b056-5ffcb8096c85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_path_ = Path('./Tables_final')\n",
    "if not os.path.exists(my_path_):\n",
    "    os.makedirs(my_path_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188735c3-caf9-49f9-9b5a-657794b4389c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#set preprints considered : no missing informations: publication_date, authors, concepts, references #in time window 2000-2024\n",
    "\n",
    "works = read_parquet(basepath3 / 'works3')\n",
    "works = works.sort_values(by=['publication_date','work_id'])\n",
    "\n",
    "works_authors_aff = read_parquet(basepath3 / 'works_authors_aff') #authors\n",
    "\n",
    "works_concepts = pd.read_parquet(os.path.join(basepath3, 'works_concepts'), engine='pyarrow') #concepts\n",
    "works_concepts = works_concepts.sort_values(by=['publication_date','work_id']).set_index('publication_date_1',drop=True)\n",
    "\n",
    "#restrict to ArXiv preprints\n",
    "basepath6 = Path('/N/project/openalex/slices/arxiv-preprints/dec-2024') \n",
    "arxiv_categories = read_parquet(basepath6 / 'preprint_categories')\n",
    "arxiv_categories = arxiv_categories[arxiv_categories['where']=='arxiv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e65fa8d-3e0c-4b9d-9db5-f86a37237078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6402f7b3-c3ce-42cf-be29-f0b79a4d29ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprints_set1 = set(works.work_id)\n",
    "preprints_set2 = set(works_authors_aff.work_id)\n",
    "preprints_set3 = set(works_concepts.work_id)\n",
    "preprints_set4 = set(arxiv_categories.work_id)\n",
    "preprint_id_set_final = ((preprints_set1.intersection(preprints_set2)).intersection(preprints_set3)).intersection(preprints_set4)\n",
    "print(f'{len(preprint_id_set_final)} preprints (arxiv, no missing info)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bb5e32-486b-4f78-b16d-86c3d87f80db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#restrict to no solo papers\n",
    "with open(os.path.join(basepath3, \"preprint_id_set_solo.pickle\"),\"rb\") as fp:\n",
    "    preprint_id_set_solo = pickle.load(fp)\n",
    "with open(os.path.join(basepath3, \"preprint_id_set_nosolo.pickle\"),\"rb\") as fp:\n",
    "    preprint_id_set_nosolo = pickle.load(fp)\n",
    "preprint_id_set_solo = preprint_id_set_solo.intersection(preprint_id_set_final)\n",
    "preprint_id_set_nosolo = preprint_id_set_nosolo.intersection(preprint_id_set_final)\n",
    "pickle.dump(preprint_id_set_solo, open(os.path.join(my_path_, \"preprint_id_set_solo.pickle\"), 'wb'))\n",
    "pickle.dump(preprint_id_set_nosolo, open(os.path.join(my_path_, \"preprint_id_set_nosolo.pickle\"), 'wb'))\n",
    "preprint_id_set_final = preprint_id_set_final.intersection(preprint_id_set_nosolo)\n",
    "\n",
    "print(f'{len(preprint_id_set_final)} preprints (arxiv, no missing info, no solo)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6c79b9-68a7-4025-bb3a-d3a6457f483e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pickle.dump(preprint_id_set_final, open(os.path.join(my_path_, \"preprint_id_set.pickle\"), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14a270e-fdc3-47aa-bfe7-75d74f6a3feb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ec7722-c246-4354-8699-eb4d949a73cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "works = works[works.work_id.isin(preprint_id_set_final)]\n",
    "works_authors_aff = works_authors_aff[works_authors_aff.work_id.isin(preprint_id_set_final)]\n",
    "works_concepts = works_concepts[works_concepts.work_id.isin(preprint_id_set_final)]\n",
    "works.to_parquet(os.path.join(my_path_, \"works\"))\n",
    "works_authors_aff.to_parquet(os.path.join(my_path_, \"works_authors_aff\"))\n",
    "works_concepts.to_parquet(os.path.join(my_path_, \"works_concepts\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45abfec6-a145-43b4-b930-20bd6cd34eeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(basepath3, \"preprint_id_set_COVID\"),\"rb\") as fp:\n",
    "    preprint_id_set_COVID = pickle.load(fp)\n",
    "with open(os.path.join(basepath3, \"preprint_id_set_noCOVID\"),\"rb\") as fp:\n",
    "    preprint_id_set_noCOVID = pickle.load(fp)\n",
    "preprint_id_set_COVID = preprint_id_set_COVID.intersection(preprint_id_set_final)\n",
    "preprint_id_set_noCOVID = preprint_id_set_noCOVID.intersection(preprint_id_set_final)\n",
    "pickle.dump(preprint_id_set_COVID, open(os.path.join(my_path_, 'preprint_id_set_COVID'), 'wb'))\n",
    "pickle.dump(preprint_id_set_noCOVID, open(os.path.join(my_path_, 'preprint_id_set_noCOVID'), 'wb'))\n",
    "works_COVID = works.query('work_id.isin(@preprint_id_set_COVID)')\n",
    "works_noCOVID = works.query('work_id.isin(@preprint_id_set_noCOVID)')\n",
    "works_COVID.to_parquet(os.path.join(my_path_, \"works_COVID\"))\n",
    "works_noCOVID.to_parquet(os.path.join(my_path_, \"works_noCOVID\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b70d418-43bf-44f5-b923-e367a6852e41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ba5055-f811-4b20-abc0-e2ddba3c21d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(basepath3, \"count_ref_df.pickle\"),\"rb\") as fp:\n",
    "    count_ref_df = pickle.load(fp)\n",
    "with open(os.path.join(basepath3, \"count_cit_df.pickle\"),\"rb\") as fp:\n",
    "    count_cit_df = pickle.load(fp)\n",
    "with open(os.path.join(basepath3, \"preprint_id_set_noref.pickle\"),\"rb\") as fp:\n",
    "    preprint_id_set_noref = pickle.load(fp)\n",
    "with open(os.path.join(basepath3, \"preprint_id_set_nocit.pickle\"),\"rb\") as fp:\n",
    "    preprint_id_set_nocit = pickle.load(fp)\n",
    "    \n",
    "count_ref_df = count_ref_df[count_ref_df.work_id.isin(preprint_id_set_final)]\n",
    "count_ref_df.to_parquet(os.path.join(my_path_, \"count_ref_df\"))\n",
    "count_cit_df = count_cit_df[count_cit_df.work_id.isin(preprint_id_set_final)]\n",
    "count_cit_df.to_parquet(os.path.join(my_path_, \"count_cit_df\"))\n",
    "\n",
    "\n",
    "preprint_id_set_noref = preprint_id_set_noref.intersection(preprint_id_set_final)\n",
    "preprint_id_set_nocit = preprint_id_set_nocit.intersection(preprint_id_set_final)\n",
    "pickle.dump(preprint_id_set_noref, open(os.path.join(my_path_, 'preprint_id_set_noref.pickle'), 'wb'))\n",
    "pickle.dump(preprint_id_set_nocit, open(os.path.join(my_path_, 'preprint_id_set_nocit.pickle'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5900c60c-e8c1-4b40-8f81-1f7231ac0238",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprint_ref_concepts_max_unique = read_parquet(basepath3 / 'preprint_ref_concepts_max_unique')\n",
    "preprint_ref_concepts_max_unique = preprint_ref_concepts_max_unique.reset_index(drop=True)\n",
    "preprint_ref_concepts_max_unique.to_parquet(os.path.join(my_path_, \"preprint_ref_concepts_max_unique\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87220f2a-fb54-4678-ad7e-f6fcae295635",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "works_referenced_works_max_unique = read_parquet(basepath3 / 'works_referenced_works_max_unique')\n",
    "works_referenced_works_max_unique.to_parquet(os.path.join(my_path_, \"works_referenced_works_max_unique\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60556a4a-ce10-4484-afd3-c042be881b67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "works_referenced_works = read_parquet(basepath3 / 'works_referenced_works')\n",
    "works_referenced_works.to_parquet(os.path.join(my_path_, \"works_referenced_works\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60f554c-4401-4d38-826e-a0dfd6a8be0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "I_dist = read_parquet(basepath3 / 'I_dist_threshold')\n",
    "I_dist.to_parquet(os.path.join(my_path_, \"I_dist_threshold\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cb436a-7476-4e51-8a08-cd9e10cab41f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5f398b-0f24-49e2-9b79-915591e537a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#whole dataset not only preprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c24948-615a-4ebe-817a-b10bb928a9f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "works_all = read_parquet(basepath3 / 'works_all')\n",
    "works_authorships_all_drop = read_parquet(basepath3 / 'works_authorships_all_drop') #no institutions info \n",
    "works_referenced_works_credit = read_parquet(basepath3 / 'works_referenced_works_credit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f58b1b9-9577-4618-8e2a-06addc535b4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#no time window restriction past\n",
    "works_all = works_all.loc['1800-01-01' : '2024-12-01']\n",
    "works_authorships_all_drop = works_authorships_all_drop.loc['1800-01-01' : '2024-12-01']\n",
    "works_referenced_works_credit = works_referenced_works_credit[works_referenced_works_credit.work_publication_date_1<'2025']\n",
    "works_referenced_works_credit = works_referenced_works_credit[works_referenced_works_credit.referenced_work_publication_date_1<'2025']\n",
    "works_referenced_works_credit = works_referenced_works_credit[works_referenced_works_credit.work_publication_date_1>='1800']\n",
    "works_referenced_works_credit = works_referenced_works_credit[works_referenced_works_credit.referenced_work_publication_date_1>='1800']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cbc3f4-ced1-401e-b9a0-a8162bc58fe5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#check all preprints included\n",
    "with open(os.path.join(my_path_, \"preprint_id_set_solo.pickle\"),\"rb\") as fp:\n",
    "    preprint_id_set_solo = pickle.load(fp)\n",
    "with open(os.path.join(my_path_, \"preprint_id_set_nosolo.pickle\"),\"rb\") as fp:\n",
    "    preprint_id_set_nosolo = pickle.load(fp)\n",
    "preprint_id_set_final_ = preprint_id_set_nosolo.union(preprint_id_set_solo)\n",
    "\n",
    "works_set1 = set(works_all.work_id)\n",
    "works_set2 = set(works_authorships_all_drop.drop_duplicates('work_id').work_id)\n",
    "works_set_final = works_set1.intersection(works_set2)\n",
    "print(f'{len(works_set_final)} considered works')\n",
    "\n",
    "print(len(preprint_id_set_final_))\n",
    "print(len(works_set1.intersection(preprint_id_set_final_)))\n",
    "print(len(works_set2.intersection(preprint_id_set_final_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667bf1ce-e5b1-44d8-87ba-76d8e59f7319",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#works_authorships_all_drop already restricted to work_id in works_all because merge\n",
    "#works_referenced_works_credit already restricted to have authors and date_publication info \n",
    "works_all = works_all[works_all.work_id.isin(works_set_final)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1418dff9-8063-4d1f-97f0-f032a9227c43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "works_all.to_parquet(os.path.join(my_path_, \"works_all\"))\n",
    "works_authorships_all_drop.to_parquet(os.path.join(my_path_, \"works_authorships_all_drop\"))\n",
    "works_referenced_works_credit.to_parquet(os.path.join(my_path_, \"works_referenced_works_credit\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026fb54f-d4dc-4e81-ad3c-a7256fd5c6cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3117a6ba-2516-4836-babe-a578bb672fe5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#copy manually because less slow\n",
    "with open(os.path.join(basepath3, \"works_month_dict.pickle\"),\"rb\") as fp:\n",
    "    works_month_dict = pickle.load(fp)\n",
    "pickle.dump(works_month_dict, open(os.path.join(my_path_, \"works_month_dict.pickle\"), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad8fb3a-4f1e-4e0f-bf50-7958b0e7d177",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb8e173d-f082-46f5-861e-84708f08965c",
   "metadata": {},
   "source": [
    "## Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2f4834-2107-4862-a139-2cbf92a4adfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_file = \"preprint_id_doi_dict.pickle\"\n",
    "with open(os.path.join(basepath3, my_file),\"rb\") as fp:\n",
    "    preprint_id_doi_dict = pickle.load(fp)\n",
    "preprint_doi_id_dict = dict((v, k) for k, v in preprint_id_doi_dict.items())\n",
    "my_file = \"preprint_id_set.pickle\"\n",
    "with open(os.path.join(my_path_, my_file),\"rb\") as fp:\n",
    "    preprint_id_set = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6703230e-e4f6-485c-b050-ba25de56e9e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "basepath6 = Path('/N/project/openalex/slices/arxiv-preprints/dec-2024') \n",
    "arxiv_categories = read_parquet(basepath6 / 'preprint_categories')\n",
    "arxiv_categories = arxiv_categories[arxiv_categories['work_id'].notnull()].reset_index(drop=True)\n",
    "arxiv_categories['work_id'] = arxiv_categories['work_id'].astype(int)\n",
    "arxiv_categories = arxiv_categories.query('work_id.isin(@preprint_id_set)') #restrict work ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f748439-5ce7-478c-b5c8-d42b7f942115",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set(arxiv_categories['where'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25e6a16-82ef-420a-8421-e6bdad2ce377",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Arxiv multiple categories\n",
    "print(len(set(arxiv_categories.id)))\n",
    "print(len(arxiv_categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47248615-01e0-4f5f-b081-ebcee522c854",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Analysis arxiv\n",
    "cat_code_count_df = arxiv_categories.groupby('id').cat_code.count().to_frame().reset_index().groupby('cat_code').id.count().to_frame()\n",
    "cat_code_count_df.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5aafc1-bde1-4807-ab50-0bcf5a2af499",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_file = \"cat_code_count_df.pickle\"\n",
    "pickle.dump(cat_code_count_df, open(os.path.join(basepath3, my_file), 'wb'))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.bar(list(cat_code_count_df.index), list(cat_code_count_df.id))\n",
    "#ax.set_title('Number of ArXiv categories assigned to each paper') \n",
    "#plt.show()\n",
    "plt.savefig(os.path.join(basepath3, 'cat_code_count.png'), bbox_inches='tight', pad_inches=0.02)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3cd94d-769a-4664-bd17-3f149b00647e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "arxiv_categories['taxonomy'] = arxiv_categories['cat_code'].str.split('.',1).str[0]\n",
    "\n",
    "#https://arxiv.org/category_taxonomy #https://arxiv.org/\n",
    "taxt_name_dict = {\n",
    "    'cs':'Computer Science',\n",
    "    'econ':'Economics',\n",
    "    'eess':'Electrical Engineering and Systems Science',\n",
    "    'math':'Mathematics',\n",
    "    'astro-ph':'Physics',\n",
    "    'cond-mat':'Physics',\n",
    "    'gr-qc':'Physics',\n",
    "    'hep-ex':'Physics',\n",
    "    'hep-lat':'Physics',\n",
    "    'hep-ph':'Physics',\n",
    "    'hep-th':'Physics',\n",
    "    'math-ph':'Physics',\n",
    "    'nlin':'Physics',\n",
    "    'nucl-ex':'Physics',\n",
    "    'nucl-th':'Physics',\n",
    "    'physics':'Physics',\n",
    "    'quant-ph':'Physics',\n",
    "    'acc-phys':'Physics',\n",
    "    'q-bio':'Biology', #'Quantitative Biology', # union with BioMed\n",
    "    'q-fin':'Quantitative Finance',\n",
    "    'stat':'Statistics',    \n",
    "    'acc-phys':'Physics',\n",
    "     'adap-org':'Physics',\n",
    "     'alg-geom':'Mathematics',\n",
    "     'ao-sci':'Physics',\n",
    "     'atom-ph':'Physics',\n",
    "     'bayes-an':'Physics',\n",
    "     'chao-dyn':'Physics',\n",
    "     'chem-ph':'Physics',\n",
    "     'cmp-lg':'Computer Science',\n",
    "     'comp-gas':'Physics',\n",
    "     'dg-ga':'Mathematics',\n",
    "     'funct-an':'Mathematics',\n",
    "     'mtrl-th':'Physics',\n",
    "     'patt-sol':'Physics',\n",
    "     'plasm-ph':'Physics',\n",
    "     'q-alg':'Mathematics',\n",
    "     'solv-int':'Physics',\n",
    "     'supr-con':'Physics',   \n",
    "}\n",
    "\n",
    "arxiv_categories['tax_name'] = arxiv_categories['taxonomy'].map(taxt_name_dict)\n",
    "arxiv_categories_list = list(set(arxiv_categories['tax_name']))\n",
    "arxiv_categories_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11bce58-3c7f-48c6-856d-105419eef414",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "arxiv_categories = arxiv_categories.drop_duplicates(['id','tax_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59915d6-03be-4fa4-be6e-7b83f36bde69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tax_name_count_df = arxiv_categories.groupby('id').tax_name.count().to_frame().reset_index().groupby('tax_name').id.count().to_frame()\n",
    "tax_name_count_df.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cc8d22-750f-48aa-9954-f38123c576ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.bar(list(tax_name_count_df.index), list(tax_name_count_df.id))\n",
    "plt.savefig(os.path.join(basepath3, 'tax_name_count.png'), bbox_inches='tight', pad_inches=0.02)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a5149b-3baa-4407-8750-f93995bbcb0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tax_name_count_df['perc'] = (tax_name_count_df['id']/len(set(arxiv_categories.id)))*100\n",
    "my_file = \"tax_name_count_df.pickle\"\n",
    "pickle.dump(tax_name_count_df, open(os.path.join(basepath3, my_file), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57804ba-03c2-41da-9f90-23892122df82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.bar(list(tax_name_count_df.index), list(tax_name_count_df.perc))\n",
    "plt.savefig(os.path.join(basepath3, 'tax_name_perc.png'), bbox_inches='tight', pad_inches=0.02) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f378f73-5cb8-4245-a838-b811c97aa0d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprint_df = arxiv_categories[['work_id','cat_code','where','tax_name']].reset_index(drop=True)\n",
    "my_file = \"preprint_df.pickle\"\n",
    "pickle.dump(preprint_df, open(os.path.join(my_path_, my_file), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d45566b-b55c-4512-9046-57c698077c6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprint_df = preprint_df[['work_id','tax_name']]\n",
    "preprint_dict = preprint_df.groupby('tax_name').work_id.apply(set).to_dict()\n",
    "my_file = \"preprint_dict.pickle\"\n",
    "pickle.dump(preprint_dict, open(os.path.join(basepath3, my_file), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c72755-69fb-4eae-977c-9461fcb4a430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a04983-24d4-4cb7-9d83-cae5f2664fb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f886a784-b1b0-4395-a018-aac528d481d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## level 1\n",
    "basepath5 = Path('/N/project/openalex/slices/arxiv-preprints/dec-2024')\n",
    "arxiv_categories = read_parquet(basepath5 / 'preprint_categories')\n",
    "\n",
    "preprint_level1_df = arxiv_categories.drop_duplicates(['id','cat_code'])\n",
    "\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/006734', 'cat_code'] = 'Evolutionary Biology'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/010041', 'cat_code'] = 'Ecology'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/010181', 'cat_code'] = 'Ecology'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/010520', 'cat_code'] = 'Ecology'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/010793', 'cat_code'] = 'Ecology'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/011742', 'cat_code'] = 'Ecology'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/011932', 'cat_code'] = 'Ecology'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/012716', 'cat_code'] = 'Ecology'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/012666', 'cat_code'] = 'Ecology'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/013086', 'cat_code'] = 'Ecology'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/022285', 'cat_code'] = 'Genetics'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/023598', 'cat_code'] = 'Evolutionary Biology'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/024802', 'cat_code'] = 'Ecology'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/026575', 'cat_code'] = 'Ecology'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/029173', 'cat_code'] = 'Evolutionary Biology'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/029165', 'cat_code'] = 'Ecology'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/029330', 'cat_code'] = 'Neuroscience'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/030031', 'cat_code'] = 'Ecology'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/030601', 'cat_code'] = 'Biochemistry'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/031161', 'cat_code'] = 'Ecology'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/031849', 'cat_code'] = 'Ecology'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/033282', 'cat_code'] = 'Ecology'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/033373', 'cat_code'] = 'Evolutionary Biology'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/034926', 'cat_code'] = 'Evolutionary Biology'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/035295', 'cat_code'] = 'Genomics'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/035915', 'cat_code'] = 'Evolutionary Biology'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/035980', 'cat_code'] = 'Neuroscience'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/036731', 'cat_code'] = 'Evolutionary Biology'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/045872', 'cat_code'] = 'Developmental Biology'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/058453', 'cat_code'] = 'Evolutionary Biology'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/061754', 'cat_code'] = 'Animal Behavior And Cognition'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/064311', 'cat_code'] = 'Evolutionary Biology'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/065516', 'cat_code'] = 'Biophysics'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/065664', 'cat_code'] = 'Biophysics'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/070631', 'cat_code'] = 'Scientific Communication And Education'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/074104', 'cat_code'] = 'Ecology'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/073734', 'cat_code'] = 'Neuroscience'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/074310', 'cat_code'] = 'Genomics'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/076653', 'cat_code'] = 'Cancer Biology'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/077057', 'cat_code'] = 'Genomics'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/079533', 'cat_code'] = 'Biophysics'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/008813', 'cat_code'] = 'Ecology'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/009597', 'cat_code'] = 'Ecology'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/009589', 'cat_code'] = 'Ecology'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/011965', 'cat_code'] = 'Ecology'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/012104', 'cat_code'] = 'Ecology'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/013680', 'cat_code'] = 'Ecology'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/029777', 'cat_code'] = 'Ecology'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/030015', 'cat_code'] = 'Ecology'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/036491', 'cat_code'] = 'Biophysics'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/052076', 'cat_code'] = 'Cancer Biology'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/058933', 'cat_code'] = 'Biophysics'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/069468', 'cat_code'] = 'Scientific Communication and Education'\n",
    "preprint_level1_df.loc[preprint_level1_df['id']=='10.1101/073999', 'cat_code'] = 'Bioinformatics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18f6584-3955-4e00-b2df-afc7769eba1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprint_level1_df = preprint_level1_df[preprint_level1_df['cat_code'].notnull()]\n",
    "\n",
    "preprint_level1_df['cat_code'] = preprint_level1_df['cat_code'].apply(lambda x: x.rstrip())\n",
    "\n",
    "#overlapping categories\n",
    "preprint_level1_df.loc[preprint_level1_df['cat_code']=='q-bio.BM', 'cat_code'] = 'Molecular Biology'\n",
    "preprint_level1_df.loc[preprint_level1_df['cat_code']=='q-bio.CB', 'cat_code'] = 'Cell Biology'\n",
    "preprint_level1_df.loc[preprint_level1_df['cat_code']=='q-bio.GN', 'cat_code'] = 'Genomics'\n",
    "preprint_level1_df.loc[preprint_level1_df['cat_code']=='q-bio.NC', 'cat_code'] = 'Neuroscience'\n",
    "preprint_level1_df.loc[preprint_level1_df['cat_code']=='q-bio.PE', 'cat_code'] = 'Evolutionary Biology'\n",
    "preprint_level1_df.loc[preprint_level1_df['cat_code']=='q-bio.SC', 'cat_code'] = 'Subcellular Processes'\n",
    "preprint_level1_df.loc[preprint_level1_df['cat_code']=='q-bio.TO', 'cat_code'] = 'Tissues and Organs'\n",
    "\n",
    "preprint_cat_set = set(preprint_level1_df.cat_code)\n",
    "print(f'{len(preprint_cat_set)} preprint categories')\n",
    "\n",
    "my_file = \"preprint_level1_df.pickle\"\n",
    "pickle.dump(preprint_level1_df, open(os.path.join(my_path_, my_file), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc01aae-5685-4394-a360-234c69fb939b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e039fa4-5a17-4344-bbbd-79874c3b715a",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f24cdf-1304-4905-b11c-bb65f6c36d8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#time restriction\n",
    "works = read_parquet(my_path_ / 'works')\n",
    "works_all = read_parquet(my_path_ / 'works_all')\n",
    "works_authors_aff = read_parquet(my_path_ / 'works_authors_aff')\n",
    "print(f\"{len(works)} preprints between [2000-01-01: 2024-12-01]\")\n",
    "print(f\"{len(works_all)} OpenAlex works between [2000-01-01: 2024-12-01]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6152ba9-3bdf-4a9e-b4ae-772743abec6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#number papers\n",
    "works_count = works.reset_index().groupby('publication_date_1').work_id.count().to_frame().reset_index()\n",
    "my_file = \"works_count.pickle\"\n",
    "pickle.dump(works_count, open(os.path.join(my_path_, my_file), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05bc852-f9ed-4927-85fe-e9ac31e79586",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_file = \"works_count.pickle\"\n",
    "with open(os.path.join(my_path_, my_file),\"rb\") as fp:\n",
    "    works_count = pickle.load(fp)\n",
    "print(f'{sum(works_count.work_id)} preprints') #1.8M\n",
    "plot_(works_count,'publication_date_1','work_id','month','Mounthly count preprints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4010beb3-6d2d-442c-ae94-47f13432ee30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320a7e98-1614-4572-aa28-ebb46fb1c7cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#number of authors\n",
    "authors_count = works_authors_aff.groupby('publication_date_1').author_id.nunique().to_frame().reset_index()\n",
    "my_file = \"authors_count.pickle\"\n",
    "pickle.dump(authors_count, open(os.path.join(my_path_, my_file), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1860171a-e4f0-47c9-bf2c-7ae0bf1b65d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_file = \"authors_count.pickle\"\n",
    "with open(os.path.join(my_path_, my_file),\"rb\") as fp:\n",
    "    authors_count = pickle.load(fp)\n",
    "print(f'{sum(authors_count.author_id)} authors preprints') \n",
    "plot_(authors_count,'publication_date_1','author_id','month','Mounthly count authors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf90f74-7dd4-4475-ba74-989b0062a6b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#number papers\n",
    "authors_mean = works.reset_index().groupby('publication_date_1').num_authors.mean().to_frame().reset_index()\n",
    "my_file = \"authors_mean.pickle\"\n",
    "pickle.dump(authors_mean, open(os.path.join(my_path_, my_file), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba6ae14-62af-4dd0-bf73-ca04e961c1fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_file = \"authors_mean.pickle\"\n",
    "with open(os.path.join(my_path_, my_file),\"rb\") as fp:\n",
    "    authors_mean = pickle.load(fp)\n",
    "plot_(authors_mean,'publication_date_1','num_authors','month','Mounthly average number authors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62bbeb3-e962-4d64-9e29-75959e2b4f73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0631369a-9c77-463b-b15c-e430e7a2ccda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#tables\n",
    "\n",
    "works_COVID = read_parquet(my_path_ / 'works_COVID')\n",
    "works_noCOVID = read_parquet(my_path_ / 'works_noCOVID')\n",
    "\n",
    "works_count_COVID_df = works_COVID.groupby(by='publication_date_1').work_id.count().to_frame().reset_index()\n",
    "my_file = \"works_count_COVID_df.pickle\"\n",
    "pickle.dump(works_count_COVID_df, open(os.path.join(my_path_, my_file), 'wb'))\n",
    "works_count_noCOVID_df = works_noCOVID.groupby(by='publication_date_1').work_id.count().to_frame().reset_index()\n",
    "my_file = \"works_count_noCOVID_df.pickle\"\n",
    "pickle.dump(works_count_noCOVID_df, open(os.path.join(my_path_, my_file), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0d57eb-15de-41c2-b38e-8bf12281aee6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "works_count_COVID_df = works_count_COVID_df[works_count_COVID_df.publication_date_1>='2019-06-01']\n",
    "works_count_COVID_df = works_count_COVID_df[works_count_COVID_df.publication_date_1<='2024-12-01']\n",
    "works_count_noCOVID_df = works_count_noCOVID_df[works_count_noCOVID_df.publication_date_1>='2019-06-01']\n",
    "works_count_noCOVID_df = works_count_noCOVID_df[works_count_noCOVID_df.publication_date_1<='2024-12-01']\n",
    "\n",
    "plt.style.use(\"dark_background\")\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "x_data = list(works_count_COVID_df['publication_date_1'])\n",
    "y_mean = works_count_COVID_df['work_id']\n",
    "ax.plot(x_data, y_mean, \"o-\",markersize=3,label='COVID')\n",
    "y_mean2 = works_count_noCOVID_df['work_id']\n",
    "ax.plot(x_data, y_mean2, \"o-\",markersize=3,label='not COVID')\n",
    "ax.set_yscale('log')\n",
    "ax.axvline(pd.Timestamp(2020, 3, 1),color='r')\n",
    "plt.grid(True, linewidth=0.5)\n",
    "ax.set_xlabel('month',size=20)\n",
    "ax.set_title('Mounthly count preprints - COVID/noCOVID (log)',size=30)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b6a60e-c3fb-4fbc-8ff7-210654421aeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "works_COVID = works_COVID[['work_id']].reset_index()\n",
    "works_COVID_count_df = works_COVID.groupby('publication_date_1').work_id.count().to_frame().rename(columns={'work_id':'work_id_COVID'}).reset_index()\n",
    "works_count = works_count.rename(columns={'work_id':'work_id_tot'})\n",
    "works_COVID_count_df = works_COVID_count_df.merge(works_count,on='publication_date_1')\n",
    "works_COVID_count_df['work_id_COVID_perc'] = works_COVID_count_df['work_id_COVID']/works_COVID_count_df['work_id_tot']\n",
    "my_file = \"works_COVID_count_df.pickle\"\n",
    "pickle.dump(works_COVID_count_df, open(os.path.join(my_path_, my_file), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c407e6ba-174c-468d-96a0-5e8cefc55295",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_file = \"works_COVID_count_df.pickle\"\n",
    "with open(os.path.join(my_path_, my_file),\"rb\") as fp:\n",
    "    works_COVID_count_df = pickle.load(fp)\n",
    "\n",
    "plt.style.use(\"dark_background\")\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "x_data = list(works_COVID_count_df['publication_date_1'])\n",
    "y_mean = works_COVID_count_df['work_id_COVID_perc']\n",
    "ax.plot(x_data, y_mean, \"o-\", color = 'orange',markersize=3)\n",
    "\n",
    "ax.axvline(pd.Timestamp(2020, 3, 1),color='r')\n",
    "plt.grid(True, linewidth=0.5)\n",
    "ax.set_xlabel('month',size=20)\n",
    "ax.set_title('Monthly Percentage Works tagged with COVID',size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52276e5b-f7ed-4a52-a5fd-d0144b4244c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daae0e76-16ed-40dd-90a4-888d877a17c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#average number of references\n",
    "ref_mean = works.reset_index().groupby('publication_date_1').ref_count.mean().to_frame().reset_index()\n",
    "my_file = \"ref_mean.pickle\"\n",
    "pickle.dump(ref_mean, open(os.path.join(my_path_, my_file), 'wb'))\n",
    "plot_(ref_mean,'publication_date_1','ref_count','month','Mounthly average number references')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2ba75d-49dc-4369-9c4a-1e73c8303233",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c1f9a2-205c-4e14-b3a9-2c3bc2ccdfce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list(preprint_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f955d891-22d3-4d0d-8f8e-34272e2f76a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# my_file = \"preprint_df.pickle\"\n",
    "# with open(os.path.join(basepath3, my_file),\"rb\") as fp:\n",
    "#     preprint_df = pickle.load(fp)\n",
    "# preprint_categories_list = list(set(preprint_df['tax_name']))\n",
    "\n",
    "my_file = \"preprint_dict.pickle\"\n",
    "with open(os.path.join(basepath3, my_file),\"rb\") as fp:\n",
    "    preprint_dict = pickle.load(fp)\n",
    "preprint_categories_list = list(preprint_dict.keys())\n",
    "\n",
    "\n",
    "my_file = \"preprint_categories_list.pickle\"\n",
    "pickle.dump(preprint_categories_list, open(os.path.join(basepath3, my_file), 'wb'))\n",
    "\n",
    "preprint_categories_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe5543a-c6fa-4f6e-b9b4-bb01a2347067",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#plot number of works and authors per month\n",
    "\n",
    "import matplotlib.dates as dates\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "def form(x,pos):\n",
    "    if x<1e3:\n",
    "        return '%1.3f' % (x)\n",
    "    elif x<1e6:\n",
    "        return '%1.1fK' % (x * 1e-3)\n",
    "    else:\n",
    "        return '%1.1fM' % (x * 1e-6)\n",
    "formatter = FuncFormatter(form)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "# x_data = []\n",
    "# for y in range(2008,2025): \n",
    "#     for m in range(1,13):\n",
    "#         x_data.append(pd.Timestamp(y, m, 1))\n",
    "# x_data = x_data[2:-11]\n",
    "# len(x_data)\n",
    "\n",
    "print('Whole Dataset')\n",
    "WORKS_COUNT = works.groupby('publication_date_1').work_id.nunique().to_frame()\n",
    "x_data = WORKS_COUNT.index\n",
    "ax.plot(x_data, WORKS_COUNT.work_id, markersize=6,label='whole dataset')\n",
    "WORKS_COUNT = WORKS_COUNT.rename(columns={'work_id':'Whole Dataset'})\n",
    "WORKS_COUNT_DF = WORKS_COUNT\n",
    "\n",
    "for n in range(len(preprint_categories_list)):\n",
    "    subfield = preprint_categories_list[n]\n",
    "    print(subfield)\n",
    " \n",
    "    #work_id_set = set(preprint_df[preprint_df['tax_name']==subfield].work_id)\n",
    "    work_id_set = preprint_dict[subfield]\n",
    "\n",
    "    works_sub = works.query('work_id.isin(@work_id_set)').sort_index()\n",
    "#     works_authorships_sub = works_authorships.query('work_id.isin(@work_id_set)').sort_index()\n",
    "#     works_authorships_drop_sub = works_authorships_sub.drop_duplicates(subset=['work_id','author_id'])\n",
    "    \n",
    "    WORKS_COUNT = works_sub.groupby('publication_date_1').work_id.nunique().to_frame()\n",
    "    WORKS_COUNT = WORKS_COUNT.reindex(x_data) #some months zero works\n",
    "    ax.plot(x_data, WORKS_COUNT.work_id, markersize=6,label=subfield)\n",
    "    WORKS_COUNT = WORKS_COUNT.rename(columns={'work_id':subfield})\n",
    "    WORKS_COUNT_DF = pd.merge(WORKS_COUNT_DF,WORKS_COUNT, left_index=True, right_index=True)\n",
    "    \n",
    "ax.yaxis.set_major_formatter(formatter)\n",
    "ax.set_title('Subfields - works',size=30)\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %y')) \n",
    "ax.axvline(pd.Timestamp(2020, 3, 1),color='r') #ax.axvline(x_dates[84],color='r') \n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "ax.grid(True, linewidth=0.5)\n",
    "#plt.savefig(os.path.join('Graphs_collab', 'Subfields - works (2).png'), bbox_inches='tight', pad_inches=0.02)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24128c33-5c04-4f28-9098-c62e6e2778bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_file = \"WORKS_COUNT_DF.pickle\"\n",
    "pickle.dump(WORKS_COUNT_DF, open(os.path.join(basepath3, my_file), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6900c59-0485-4acc-855b-73c888eccd01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "WORKS_COUNT_DF = WORKS_COUNT_DF[list(WORKS_COUNT_DF.sum(axis=0).to_frame().sort_values(by=0,ascending=False).index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66432202-1dd4-4f29-a7a7-bf8324279507",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "x_data = WORKS_COUNT_DF.index\n",
    "for n in range(len(list(WORKS_COUNT_DF.columns))):\n",
    "    subfield = list(WORKS_COUNT_DF.columns)[n]\n",
    "    ax.plot(x_data, WORKS_COUNT_DF[subfield], markersize=6,label=subfield)\n",
    "ax.yaxis.set_major_formatter(formatter)\n",
    "ax.set_title('Subfields - works',size=30)\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %y')) \n",
    "ax.axvline(pd.Timestamp(2020, 3, 1),color='r') #ax.axvline(x_dates[84],color='r') \n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "ax.grid(True, linewidth=0.5)\n",
    "#plt.savefig(os.path.join('Graphs_collab', 'Subfields - works (2).png'), bbox_inches='tight', pad_inches=0.02) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d7921e-cb1a-4352-bf0d-9fa4a8c02f42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig2, ax2 = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "print('Whole Dataset')\n",
    "AUTHORS_COUNT =  works_authors_aff.reset_index().groupby('publication_date_1').author_id.nunique().to_frame()\n",
    "x_data = AUTHORS_COUNT.index\n",
    "ax2.plot(x_data, AUTHORS_COUNT.author_id, markersize=6,label='whole dataset')\n",
    "AUTHORS_COUNT = AUTHORS_COUNT.rename(columns={'author_id':'Whole Dataset'})\n",
    "AUTHORS_COUNT_DF = AUTHORS_COUNT\n",
    "\n",
    "for n in range(len(preprint_categories_list)):\n",
    "    subfield = preprint_categories_list[n]\n",
    "    print(subfield)\n",
    " \n",
    "    #work_id_set = set(preprint_df[preprint_df['tax_name']==subfield].work_id)\n",
    "    work_id_set = preprint_dict[subfield]\n",
    "\n",
    "    works_sub = works.query('work_id.isin(@work_id_set)').sort_index()\n",
    "    works_authorships_fill_sub = works_authors_aff.query('work_id.isin(@work_id_set)').sort_index()\n",
    "    works_authorships_fill_drop_sub = works_authorships_fill_sub.drop_duplicates(subset=['work_id','author_id'])\n",
    "    \n",
    "    AUTHORS_COUNT = works_authorships_fill_drop_sub.groupby('publication_date_1').author_id.nunique().to_frame()\n",
    "    AUTHORS_COUNT = AUTHORS_COUNT.reindex(x_data) #some months zero works\n",
    "    ax2.plot(x_data, AUTHORS_COUNT.author_id, markersize=6,label=subfield)\n",
    "    AUTHORS_COUNT = AUTHORS_COUNT.rename(columns={'author_id':subfield})\n",
    "    AUTHORS_COUNT_DF = pd.merge(AUTHORS_COUNT_DF,AUTHORS_COUNT, left_index=True, right_index=True)\n",
    "    \n",
    "ax2.yaxis.set_major_formatter(formatter)\n",
    "ax2.set_title('Subfields - authors',size=30)\n",
    "ax2.xaxis.set_major_formatter(mdates.DateFormatter('%b %y')) \n",
    "ax2.axvline(pd.Timestamp(2020, 3, 1),color='r')\n",
    "ax2.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "ax2.grid(True, linewidth=0.5)\n",
    "#plt.savefig(os.path.join('Graphs_collab', 'Subfields - authors (2).png'), bbox_inches='tight', pad_inches=0.02)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bead69f-f25c-46c2-ad80-4e3981e45c66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_file = \"AUTHORS_COUNT_DF.pickle\"\n",
    "pickle.dump(AUTHORS_COUNT_DF, open(os.path.join(basepath3, my_file), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17b299f-dd70-4840-bd71-2788e637ab96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "WORKS_COUNT_TOT_DF = WORKS_COUNT_DF.sum().to_frame().sort_values(by=0,ascending=False).rename(columns={0:'work_count'})\n",
    "WORKS_COUNT_TOT_DF['perc'] = (WORKS_COUNT_TOT_DF['work_count']/len(preprint_categories_list))*100\n",
    "my_file = \"WORKS_COUNT_TOT_DF.pickle\"\n",
    "pickle.dump(WORKS_COUNT_TOT_DF, open(os.path.join(basepath3, my_file), 'wb'))\n",
    "WORKS_COUNT_TOT_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ab5282-f52d-4fcf-b32b-5acb2a8d3b85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
